import asyncio
import os
import urllib.parse
from collections.abc import AsyncGenerator

import streamlit as st
from dotenv import load_dotenv
from pydantic import ValidationError
from streamlit.runtime.scriptrunner import get_script_run_ctx

from client import AgentClient, AgentClientError
from schema import ChatHistory, ChatMessage
from schema.task_data import TaskData, TaskDataStatus
from components.navigation import create_navigation
from components.styles import apply_global_styles

APP_TITLE = "Smart Agent"
APP_ICON = "ğŸ¤–"


async def main() -> None:
    # è®¾ç½®é¡µé¢é…ç½®å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤
    st.set_page_config(
        page_title=APP_TITLE,
        page_icon=APP_ICON,
        menu_items={},
    )

    # åº”ç”¨å…¨å±€æ ·å¼
    apply_global_styles()

    # åˆ›å»ºå¯¼èˆª
    # create_navigation()

    if st.get_option("client.toolbarMode") != "minimal":
        st.set_option("client.toolbarMode", "minimal")
        await asyncio.sleep(0.1)
        st.rerun()

    if "agent_client" not in st.session_state:
        load_dotenv()
        agent_url = os.getenv("AGENT_URL")
        if not agent_url:
            host = os.getenv("HOST", "localhost")
            port = os.getenv("PORT", 8080)
            agent_url = f"http://{host}:{port}"
        try:
            with st.spinner("Connecting to Smart Agent service..."):
                st.session_state.agent_client = AgentClient(base_url=agent_url)
        except AgentClientError as e:
            st.error(f"Failed to connect to Smart Agent service {agent_url}: {e}")
            st.markdown("The service may be starting up, please try again later.")
            st.stop()
    agent_client: AgentClient = st.session_state.agent_client

    # å¯¹è¯ç®¡ç†æ ¸å¿ƒ
    if "thread_id" not in st.session_state:
        thread_id = st.query_params.get("thread_id")
        if not thread_id:
            thread_id = get_script_run_ctx().session_id
            messages = []
        else:
            try:
                messages: ChatHistory = agent_client.get_history(thread_id=thread_id).messages
            except AgentClientError:
                st.error("No chat history found for this thread ID.")
                messages = []
        st.session_state.messages = messages
        st.session_state.thread_id = thread_id

    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        st.header(f"{APP_ICON} {APP_TITLE}")
        ""
        "AI Smart Assistant System built on LangGraph, FastAPI, and Streamlit"
        with st.popover(":material/settings: Settings", use_container_width=True):
            model_idx = agent_client.info.models.index(agent_client.info.default_model)
            model = st.selectbox("Choose model", options=agent_client.info.models, index=model_idx)
            agent_list = [a.key for a in agent_client.info.agents]
            agent_idx = agent_list.index(agent_client.info.default_agent)
            agent_client.agent = st.selectbox(
                "Choose Agent",
                options=agent_list,
                index=agent_idx,
            )
            use_streaming = st.toggle("Streaming Output", value=True)

        # @st.dialog("æ¶æ„")
        # def architecture_dialog() -> None:
        #     st.image(
        #         "https://github.com/JoshuaC215/agent-service-toolkit/blob/main/media/agent_architecture.png?raw=true"
        #     )
        #     "[åœ¨ Github ä¸ŠæŸ¥çœ‹å®Œæ•´å¤§å°](https://github.com/JoshuaC215/agent-service-toolkit/blob/main/media/agent_architecture.png)"
        #     st.caption(
        #         "åº”ç”¨æ‰˜ç®¡åœ¨ [Streamlit Cloud](https://share.streamlit.io/) ä¸Šï¼ŒFastAPI æœåŠ¡è¿è¡Œåœ¨ [Azure](https://learn.microsoft.com/en-us/azure/app-service/) ä¸Š"
        #     )
        #
        # if st.button(":material/schema: æ¶æ„", use_container_width=True):
        #     architecture_dialog()

        # with st.popover(":material/policy: éšç§", use_container_width=True):
        #     st.write(
        #         "æ­¤åº”ç”¨ä¸­çš„æç¤ºã€å“åº”å’Œåé¦ˆä¼šè¢«åŒ¿åè®°å½•å¹¶ä¿å­˜åˆ° LangSmithï¼Œä»…ç”¨äºäº§å“è¯„ä¼°å’Œæ”¹è¿›ã€‚"
        #     )

        @st.dialog("Share/resume chat")
        def share_chat_dialog() -> None:
            session = st.runtime.get_instance()._session_mgr.list_active_sessions()[0]
            st_base_url = urllib.parse.urlunparse(
                [session.client.request.protocol, session.client.request.host, "", "", "", ""]
            )
            if not st_base_url.startswith("https") and "localhost" not in st_base_url:
                st_base_url = st_base_url.replace("http", "https")
            chat_url = f"{st_base_url}?thread_id={st.session_state.thread_id}"
            st.markdown(f"**Chat url:**\n```text\n{chat_url}\n```")
            st.info("Copy the link above to share or resume this chat")

        if st.button(":material/upload: Share/resume chat", use_container_width=True):
            share_chat_dialog()

        # "[æŸ¥çœ‹æºä»£ç ](https://github.com/JoshuaC215/agent-service-toolkit)"
        # st.caption(
        #     "ç”± [Joshua](https://www.linkedin.com/in/joshua-k-carroll/) åœ¨ Oakland åˆ¶ä½œ"
        # )

    # ç»˜åˆ¶ç°æœ‰æ¶ˆæ¯
    messages: list[ChatMessage] = st.session_state.messages

    if len(messages) == 0:
        match agent_client.agent:
            case "chatbot":
                WELCOME = "Hello! I'm a simple chatbot. How can I assist you today?"
            case "interrupt-agent":
                WELCOME = "Hello! I'm an interrupt agent. Tell me your birthday, and I can predict your personality!"
            case "research-assistant":
                WELCOME = "Hello! I'm an AI research assistant with web search and calculator capabilities. How can I assist you today?"
            case _:
                WELCOME = "Hello! I'm an AI assistant. How can I assist you today?"
        with st.chat_message("ai"):
            st.write(WELCOME)

    # draw_messages() éœ€è¦ä¸€ä¸ªå¼‚æ­¥è¿­ä»£å™¨
    async def amessage_iter() -> AsyncGenerator[ChatMessage, None]:
        for m in messages:
            yield m

    await draw_messages(amessage_iter())

    # å¦‚æœç”¨æˆ·æä¾›äº†æ–°è¾“å…¥ï¼Œç”Ÿæˆæ–°æ¶ˆæ¯
    if user_input := st.chat_input():
        messages.append(ChatMessage(type="human", content=user_input))
        st.chat_message("human").write(user_input)
        try:
            if use_streaming:
                stream = agent_client.astream(
                    message=user_input,
                    model=model,
                    thread_id=st.session_state.thread_id,
                )
                await draw_messages(stream, is_new=True)
            else:
                response = await agent_client.ainvoke(
                    message=user_input,
                    model=model,
                    thread_id=st.session_state.thread_id,
                )
                messages.append(response)
                st.chat_message("ai").write(response.content)
            st.rerun()  # æ¸…é™¤è¿‡æ—¶çš„å®¹å™¨
        except AgentClientError as e:
            st.error(f"Error generating response: {e}")
            st.stop()

    # å¦‚æœç”Ÿæˆäº†æ¶ˆæ¯ï¼Œæ˜¾ç¤ºåé¦ˆå°éƒ¨ä»¶
    if len(messages) > 0 and st.session_state.last_message:
        with st.session_state.last_message:
            await handle_feedback()


async def draw_messages(
        messages_agen: AsyncGenerator[ChatMessage | str, None],
        is_new: bool = False,
) -> None:
    """ç»˜åˆ¶ä¸€ç»„èŠå¤©æ¶ˆæ¯ - é‡æ”¾ç°æœ‰æ¶ˆæ¯æˆ–æµå¼ä¼ è¾“æ–°æ¶ˆæ¯ã€‚"""
    last_message_type = None
    st.session_state.last_message = None

    streaming_content = ""
    streaming_placeholder = None

    while msg := await anext(messages_agen, None):
        if isinstance(msg, str):
            if not streaming_placeholder:
                if last_message_type != "ai":
                    last_message_type = "ai"
                    st.session_state.last_message = st.chat_message("ai")
                with st.session_state.last_message:
                    streaming_placeholder = st.empty()

            streaming_content += msg
            streaming_placeholder.write(streaming_content)
            continue
        if not isinstance(msg, ChatMessage):
            st.error(f"Unexpected message type: {type(msg)}")
            st.write(msg)
            st.stop()

        match msg.type:
            case "human":
                last_message_type = "human"
                st.chat_message("human").write(msg.content)

            case "ai":
                if is_new:
                    st.session_state.messages.append(msg)

                if last_message_type != "ai":
                    last_message_type = "ai"
                    st.session_state.last_message = st.chat_message("ai")

                with st.session_state.last_message:
                    if msg.content:
                        if streaming_placeholder:
                            streaming_placeholder.write(msg.content)
                            streaming_content = ""
                            streaming_placeholder = None
                        else:
                            st.write(msg.content)

                    if msg.tool_calls:
                        call_results = {}
                        for tool_call in msg.tool_calls:
                            status = st.status(
                                f"""Tool call: {tool_call["name"]}""",
                                state="running" if is_new else "complete",
                            )
                            call_results[tool_call["id"]] = status
                            status.write("Args:")
                            status.write(tool_call["args"])

                        for _ in range(len(call_results)):
                            tool_result: ChatMessage = await anext(messages_agen)

                            if tool_result.type != "tool":
                                st.error(f"Unexpected ChatMessage type: {tool_result.type}")
                                st.write(tool_result)
                                st.stop()

                            if is_new:
                                st.session_state.messages.append(tool_result)
                            if tool_result.tool_call_id:
                                status = call_results[tool_result.tool_call_id]
                            status.write("Result:")
                            status.write(tool_result.content)
                            status.update(state="complete")

            case "custom":
                try:
                    task_data: TaskData = TaskData.model_validate(msg.custom_data)
                except ValidationError:
                    st.error("Received unexpected CustomData message from assistant")
                    st.write(msg.custom_data)
                    st.stop()

                if is_new:
                    st.session_state.messages.append(msg)

                if last_message_type != "task":
                    last_message_type = "task"
                    st.session_state.last_message = st.chat_message(
                        name="task", avatar=":material/manufacturing:"
                    )
                    with st.session_state.last_message:
                        status = TaskDataStatus()

                status.add_and_draw_task_data(task_data)

            case _:
                st.error(f"Unexpected ChatMessage type: {msg.type}")
                st.write(msg)
                st.stop()


async def handle_feedback() -> None:
    """ç»˜åˆ¶åé¦ˆå°éƒ¨ä»¶å¹¶è®°å½•ç”¨æˆ·çš„åé¦ˆã€‚"""
    if "last_feedback" not in st.session_state:
        st.session_state.last_feedback = (None, None)

    latest_run_id = st.session_state.messages[-1].run_id
    feedback = st.feedback("stars", key=latest_run_id)

    if feedback is not None and (latest_run_id, feedback) != st.session_state.last_feedback:
        normalized_score = (feedback + 1) / 5.0

        agent_client: AgentClient = st.session_state.agent_client
        try:
            await agent_client.acreate_feedback(
                run_id=latest_run_id,
                key="human-feedback-stars",
                score=normalized_score,
                kwargs={"comment": "Inline user feedback"},
            )
        except AgentClientError as e:
            st.error(f"Error recording feedback: {e}")
            st.stop()
        st.session_state.last_feedback = (latest_run_id, feedback)
        st.toast("Feedback recorded", icon=":material/reviews:")


if __name__ == "__main__":
    asyncio.run(main())